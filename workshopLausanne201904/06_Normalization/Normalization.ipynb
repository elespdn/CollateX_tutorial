{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "\n",
    "There are various ways to normalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization 1. Remove and replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to the example of the sonnet about writing a sonnet, by Lope de Vega, in a French translation.\n",
    "\n",
    "The output of the collation mostly contains differences of punctuation and capitalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collatex import *\n",
    "collation = Collation()\n",
    "witness_1707 = open( \"../data/sonnet/Lope_soneto_FR_1707.txt\", encoding='utf-8' ).read()\n",
    "witness_1822 = open( \"../data/sonnet/Lope_soneto_FR_1822.txt\", encoding='utf-8' ).read()\n",
    "collation.add_plain_witness( \"wit 1707\", witness_1707 )\n",
    "collation.add_plain_witness( \"wit 1822\", witness_1822 )\n",
    "alignment_table = collate(collation, output='html2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that we are not interested in punctuation and capitalization: we only want what might be called 'substantive variants'.\n",
    "\n",
    "The \"hard way\" of obtaining the expected result is to **remove punctuation and lower-case all the texts**. The code below will do just that: it will\n",
    "- create a new directory, inside the `data/sonnet` dir, called 'norm'\n",
    "- make a normalized copy (without punctuation and all lower-case) of each file inside the new 'norm' dir\n",
    "\n",
    "The creation of a normalized copy is safer than just normalizing the original transcriptions. If you keep the originals, you can always come back to them and perform other kinds of normalization if needed.\n",
    "\n",
    "**Note**: the code below contains lots of comments, that is string that will not be executed but can be used for documentation. You've seen that in XML comments are inside <\\!-- -->. In Python, comment are marked with the sign #."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re, os\n",
    "\n",
    "path = '../data/sonnet/'  # put the path into a variable \n",
    "\n",
    "os.makedirs(path + 'norm', exist_ok=True)  # create a new folder, if does not exist\n",
    "\n",
    "files = [os.path.basename(x) for x in glob.glob(path+'*.txt')]  # take all txt files in the directory\n",
    "\n",
    "for file in files:  # for each file in the directory\n",
    "    \n",
    "    ### READ THE FILE CONTENT\n",
    "    file_opened = open(path+file, 'r', encoding='utf-8') # open the file in mode 'r' (read)\n",
    "    content = file_opened.read()  # read the file content\n",
    "    \n",
    "    ### ALL TO LOWER CASE\n",
    "    lowerContent = content.lower() \n",
    "    \n",
    "    ### REMOVE PUNCTUATION \n",
    "    # remove everything that is not alphanumeric character (\\w) or space (\\s), and substitute it with whitespace\n",
    "    noPunct_lowerContent = re.sub(r'[^\\w\\s]',' ',lowerContent) \n",
    "    \n",
    "    ### REMOVE MULTIPLE WHITESPACES\n",
    "    regularSpaces_noPunct_lowerContent = \" \".join(noPunct_lowerContent.split())\n",
    "    \n",
    "    ### CREATE A NEW FILE\n",
    "    filename = file.split('.')[0]\n",
    "    new_file = open(path+'norm/' + filename + '_norm.txt', 'w', encoding='utf-8') # open the new file in mode 'w' (write)\n",
    "    \n",
    "    ### WRITE THE NEW CONTENT INTO THE NEW FILE\n",
    "    new_file.write(regularSpaces_noPunct_lowerContent) \n",
    "    \n",
    "    ### CLOSE THE FILE\n",
    "    new_file.close()\n",
    "    \n",
    "print('Finished! All normalized!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's **collate the normalized copies**.\n",
    "\n",
    "Attention to the new path. The output should be different from the one above!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collatex import *\n",
    "collation = Collation()\n",
    "witness_1707 = open( \"../data/sonnet/norm/Lope_soneto_FR_1707_norm.txt\", encoding='utf-8' ).read()\n",
    "witness_1822 = open( \"../data/sonnet/norm/Lope_soneto_FR_1822_norm.txt\", encoding='utf-8' ).read()\n",
    "collation.add_plain_witness( \"wit 1707\", witness_1707 )\n",
    "collation.add_plain_witness( \"wit 1822\", witness_1822 )\n",
    "alignment_table = collate(collation, output='html2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization 2. Annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
